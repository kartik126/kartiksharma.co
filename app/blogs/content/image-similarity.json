{
    "slug": "image-similarity-system",
    "title": "Image Similarity System for Fashion Items",
    "description": "A deep learning-based system for comparing fashion items and determining their similarity using EfficientNet-B4 and cosine similarity.",
    "date": "2025-06-17",
    "readTime": "10 min read",
    "content": "# \nA deep learning-based system for comparing fashion items and determining their similarity. This system uses EfficientNet-B4 to extract features from images and cosine similarity to compare them.\n\n## Overview\n\nThis system can:\n- Compare fashion items and determine their similarity\n- Identify identical items\n- Distinguish between different types of clothing\n- Recognize similar items with color variations\n\n## Example Results\n\n1. **Same Item (Perfect Match)**:\n```\nImage 1: red_tshirt.webp\nImage 2: red_tshirt.webp\nSimilarity Score: 1.0000\nInterpretation: Very similar items\n```\n\n2. **Different Types of Clothing**:\n```\nImage 1: red_tshirt.webp\nImage 2: red_dress.jpg\nSimilarity Score: 0.0218\nInterpretation: Different items\n```\n\n3. **Same Type, Different Color**:\n```\nImage 1: red_tshirt.webp\nImage 2: yellow_tshirt.webp\nSimilarity Score: 0.7540\nInterpretation: Similar items with some differences\n```\n\n## Technical Details\n\n### Libraries Used\n\n```python\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport timm\n```\n\n1. **PyTorch (`torch`)**: \n   - Deep learning framework\n   - Used for loading and running pre-trained models\n   - Provides efficient tensor operations and GPU support\n\n2. **TorchVision (`transforms`)**: \n   - Image transformation utilities\n   - Used for preprocessing images\n   - Part of PyTorch ecosystem\n\n3. **PIL (`Image`)**: \n   - Python Imaging Library\n   - Used for opening and manipulating images\n   - Provides basic image processing capabilities\n\n4. **NumPy (`np`)**: \n   - Scientific computing package\n   - Used for array operations\n   - Essential for handling image data and embeddings\n\n5. **scikit-learn (`cosine_similarity`)**: \n   - Machine learning library\n   - Used for computing similarity between embeddings\n   - Provides efficient implementation of cosine similarity\n\n6. **timm**: \n   - PyTorch Image Models\n   - Provides access to various pre-trained models\n   - We're using EfficientNet-B4\n\n### Model Setup\n\n```python\n# Load pre-trained model\nmodel = timm.create_model('tf_efficientnet_b4_ns', pretrained=True)\nmodel = torch.nn.Sequential(*list(model.children())[:-1])  # Remove last layer\nmodel.eval()\n```\n\n### Image Preprocessing\n\n```python\ntransform = transforms.Compose([\n    transforms.Resize(380),  # EfficientNet-B4 input size\n    transforms.CenterCrop(380),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n```\n\n### Core Functions\n\n#### Getting Image Embeddings\n\n```python\ndef get_image_embedding(image_path):\n    # Load and transform image\n    image = Image.open(image_path).convert('RGB')\n    image_tensor = transform(image).unsqueeze(0)\n    \n    # Get embedding\n    with torch.no_grad():\n        embedding = model(image_tensor)\n        # Flatten the embedding to 1D array\n        embedding = embedding.squeeze().numpy()\n    \n    return embedding\n```\n\n#### Comparing Images\n\n```python\ndef compare_images(image1_path, image2_path):\n    # Get embeddings\n    embedding1 = get_image_embedding(image1_path)\n    embedding2 = get_image_embedding(image2_path)\n    \n    # Compute similarity\n    similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n    \n    # Print comparison results\n    print(f\"\\nImage Comparison Results:\")\n    print(f\"Image 1: {image1_path}\")\n    print(f\"Image 2: {image2_path}\")\n    print(f\"Similarity Score: {similarity:.4f}\")\n    \n    # Interpret the score\n    if similarity > 0.85:\n        print(\"\\nInterpretation: Very similar items\")\n    elif similarity > 0.7:\n        print(\"\\nInterpretation: Similar items with some differences\")\n    elif similarity > 0.5:\n        print(\"\\nInterpretation: Different items with some similarities\")\n    else:\n        print(\"\\nInterpretation: Different items\")\n    \n    return similarity\n```\n\n## How It Works\n\n1. **Feature Extraction**:\n   - The model extracts high-level features from images\n   - These features capture both structural and color information\n   - The embedding represents the image in a high-dimensional space\n\n2. **Similarity Calculation**:\n   - Cosine similarity measures the angle between embeddings\n   - Values range from -1 to 1, where 1 means identical\n   - Higher values indicate more similar items\n\n3. **Interpretation**:\n   - > 0.85: Very similar items\n   - > 0.7: Similar items with differences\n   - > 0.5: Different items with some similarities\n   - < 0.5: Different items\n```\n\n## Usage\n\n```python\n# Example usage\nimage_paths = [\n    'path/to/image1.webp',\n    'path/to/image2.webp'\n]\n\n# Compare images\nsimilarity_score = compare_images(image_paths[0], image_paths[1])\n```\n\n## Requirements\n\n- Python 3.7+\n- PyTorch\n- TorchVision\n- Pillow\n- NumPy\n- scikit-learn\n- timm",
    "tags": [
        "Computer Vision",
        "Fashion",
        "Python",
        "PyTorch",
        "EfficientNet"
    ]
}